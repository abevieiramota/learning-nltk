{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "import re\n",
    "import time # uso apenas para evitar o cache das imagens\n",
    "from IPython.core.display import display, HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read, filter, clean and structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "re_empty_line = re.compile(\"^[\\s•]+$\")\n",
    "def is_empty_line(line):\n",
    "    \n",
    "    return re_empty_line.match(line) is not None\n",
    "\n",
    "re_chapter_title = re.compile(\"^[A-ZÁÉÍÓÚÃÕ\\. ]+\\s*$\")\n",
    "def is_chapter_title(line):\n",
    "    \n",
    "    return re_chapter_title.match(line) is not None\n",
    "\n",
    "re_newline = re.compile(\"[\\r\\n]+\")\n",
    "\n",
    "def filter_and_clean(lines):\n",
    "    \n",
    "    return [re_newline.sub(\"\", line).strip() for line in lines if not is_empty_line(line)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "chapters = []\n",
    "\n",
    "# read, filter, clean and structure\n",
    "with codecs.open(\"perto_do_coracao_selvagem.txt\", \"r\", \"utf-8\") as f:\n",
    "    \n",
    "    current_chapter = {'title': '__NOT DEFINED__', 'lines': []}\n",
    "    for line in filter_and_clean(f.readlines()):\n",
    "        \n",
    "        if is_chapter_title(line):\n",
    "            \n",
    "            current_chapter = {'title': line, 'lines': []}\n",
    "            \n",
    "            chapters.append(current_chapter)\n",
    "        else:\n",
    "            \n",
    "            current_chapter['lines'].append(line)\n",
    "            \n",
    "for chapter in chapters:\n",
    "    \n",
    "    chapter['text'] = \" \".join(chapter['lines'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenize sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk.data\n",
    "\n",
    "sent_tokenizer = nltk.data.load(\"tokenizers/punkt/portuguese.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for chapter in chapters:\n",
    "    \n",
    "    chapter['sentences'] = sent_tokenizer.tokenize(chapter['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word cloud for chapters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseado em https://github.com/GaelVaroquaux/my_topics/blob/master/topics_extraction.py\n",
    "    \n",
    "Não, eu não sei o que estou fazendo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import NMF\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import nltk\n",
    "from nltk.stem import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = 20\n",
    "re_is_word_tokenizer = RegexpTokenizer(\"[\\w']+\")\n",
    "\n",
    "stemmer = SnowballStemmer(\"portuguese\")\n",
    "\n",
    "def tokenize_and_filter(sent):\n",
    "    \n",
    "    return [sent for sent in re_is_word_tokenizer.tokenize(sent) if len(sent) > 2]\n",
    "\n",
    "# n_features?\n",
    "tfidf_vec = TfidfVectorizer(max_df = .5, min_df = 4, max_features=n_features, norm='l1',\n",
    "                            stop_words=nltk.corpus.stopwords.words('portuguese'),\n",
    "                            tokenizer=tokenize_and_filter,\n",
    "                            preprocessor=stemmer.stem)\n",
    "\n",
    "all_sents = set().union(*[chapter['sentences'] for chapter in chapters])\n",
    "tfidf = tfidf_vec.fit_transform(all_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nmf = NMF(n_components=3, random_state=0).fit(tfidf)\n",
    "\n",
    "feature_names = tfidf_vec.get_feature_names()\n",
    "\n",
    "doc_loadings = nmf.transform(tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def my_color_func(word=None, font_size=None, position=None, orientation=None, font_path=None, random_state=None):\n",
    "    \n",
    "    return \"hsl(%d, 90%%, 20%%)\" % (110 + 3*font_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x, y = np.ogrid[-1:1:250j, -1:1:450j]\n",
    "mask = (255 * ((x ** 2 + y ** 2))).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "for topic_idx, topic in enumerate(nmf.components_):\n",
    "    \n",
    "    freq_cloud = WordCloud(max_font_size=100, relative_scaling=.5,\n",
    "                           background_color='white', mode='RGBA',\n",
    "                           mask=mask, color_func=my_color_func, scale=2)\n",
    "    \n",
    "    frequencies = [(w, f) for w, f in zip(feature_names, topic) if f != 0]\n",
    "    \n",
    "    freq_cloud.generate_from_frequencies(frequencies)\n",
    "    \n",
    "    freq_cloud.to_file(os.path.join('word_cloud', 'teste_%02i.png' % topic_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "random_string = str(time.time())\n",
    "\n",
    "img_1 = \"word_cloud/teste_00.png?{}\".format(random_string)\n",
    "img_2 = \"word_cloud/teste_01.png?{}\".format(random_string)\n",
    "img_3 = \"word_cloud/teste_02.png?{}\".format(random_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=word_cloud/teste_00.png?1491572279.5149539 />"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(HTML('<img src={} />'.format(img_1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=word_cloud/teste_01.png?1491572279.5149539 />"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(HTML('<img src={} />'.format(img_2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=word_cloud/teste_02.png?1491572295.6057851 />"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(HTML('<img src={} />'.format(img_3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
